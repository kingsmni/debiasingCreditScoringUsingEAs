{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from bias_functions import *\n",
    "from utility_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(setSelection):\n",
    "    if setSelection == 'toy':\n",
    "        X,y = generate_toy_data(1000,200,2)\n",
    "    elif setSelection == 'adult':\n",
    "        protectedAttributes={'race':'White','gender':'Male'}\n",
    "        X,y = load_adult(protectedAttributes=protectedAttributes)\n",
    "    elif setSelection == 'bank':\n",
    "        X,y = load_bank(smaller=True)\n",
    "    elif setSelection == 'german':\n",
    "        X,y = load_german()\n",
    "    elif setSelection == 'mortgage':\n",
    "        protectedCategoricalAttributes={'applicant_ethnicity_name':'Not Hispanic or Latino',\n",
    "                                'applicant_race_name_1':'White','applicant_sex_name':'Male'}\n",
    "        protectedNumericalAttributes=['minority_population']\n",
    "        X,y = load_mortgage(protectedCategoricalAttributes=protectedCategoricalAttributes, \\\n",
    "                            protectedNumericalAttributes=protectedNumericalAttributes)\n",
    "    else:\n",
    "        print('dataset not recognised')\n",
    "        \n",
    "    X = np.hstack([X, np.ones((X.shape[0],1))]) ## add ones to solve for affine functions\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeUnconstrainedMeasures_initOnly(trainxs,testxs,trainys,testys,sensitiveAttributeIndex=0,noOfSamplingRuns=20):\n",
    "    \n",
    "    # note that this function performs multiple runs in order to average over logistic regression initialisations\n",
    "    \n",
    "    # resultsArray: 1st dimension - train/test; 3rd dimension - col0:accuracy, col1:fairnessMeasure1, col2:fairnessMeasure2, col3:fairnessMeasure3\n",
    "    resultsArray = np.zeros((2,noOfSamplingRuns,4))\n",
    "    \n",
    "    for run in range(noOfSamplingRuns):\n",
    "        w = minimize(fun = logisticLoss,\n",
    "            x0 = np.random.rand(trainxs.shape[1],),\n",
    "            args = (trainxs, trainys),\n",
    "            method = 'SLSQP',\n",
    "            options = {\"maxiter\":100000},\n",
    "            constraints = []\n",
    "            )\n",
    "    \n",
    "        resultsArray[0,run,0] = 1-errorRate(w.x,trainxs, trainys)\n",
    "        resultsArray[1,run,0] = 1-errorRate(w.x,testxs, testys)\n",
    "\n",
    "        # fairness measures on training data\n",
    "        fairnessMeasure1 = differenceDisparateImpactModel(w.x,trainxs,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "        fairnessMeasure2 = differenceEqualOpportunity(w.x,trainxs,trainys,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "        fairnessMeasure3 = differenceDisparateMistreatment(w.x,trainxs,trainys,sensitiveAttributeIndex=sensitiveAttributeIndex,type='OMR')\n",
    "\n",
    "        resultsArray[0,run,1:] = [np.abs(fairnessMeasure1[0]-fairnessMeasure1[1]),np.abs(fairnessMeasure2[0]-fairnessMeasure2[1]),\\\n",
    "                                 np.abs(fairnessMeasure3[0]-fairnessMeasure3[1])]\n",
    "\n",
    "        # fairness measures on test data\n",
    "        fairnessMeasure1 = differenceDisparateImpactModel(w.x,testxs,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "        fairnessMeasure2 = differenceEqualOpportunity(w.x,testxs,testys,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "        fairnessMeasure3 = differenceDisparateMistreatment(w.x,testxs,testys,sensitiveAttributeIndex=sensitiveAttributeIndex,type='OMR')\n",
    "\n",
    "        resultsArray[1,run,1:] = [np.abs(fairnessMeasure1[0]-fairnessMeasure1[1]),np.abs(fairnessMeasure2[0]-fairnessMeasure2[1]),\\\n",
    "                                 np.abs(fairnessMeasure3[0]-fairnessMeasure3[1])]\n",
    "        \n",
    "    # resultsSummary: \n",
    "    # 1st dimension: train/test\n",
    "    # 2nd dimension: accuracy, fairnessMeasures (x3)\n",
    "    # 3rd dimension: col0: mean, col1: std\n",
    "    resultsSummary = np.zeros((2,4,2))\n",
    "    resultsSummary[:,:,0] = np.mean(resultsArray, axis=1)\n",
    "    resultsSummary[:,:,1] = np.std(resultsArray, axis=1)\n",
    "    \n",
    "    return resultsSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeUnconstrainedMeasures_fullRandomisation(X,y,sensitiveAttributeIndex=0,noOfSamplingRuns=20,train_size=0.8):\n",
    "    \n",
    "    # this function performs multiple runs in order to average over training/test splits and logistic regression initialisations\n",
    "    \n",
    "    # resultsArray: 1st dimension - train/test; 3rd dimension - col0:accuracy, col1:fairnessMeasure1, col2:fairnessMeasure2, col3:fairnessMeasure3\n",
    "    resultsArray = np.zeros((2,noOfSamplingRuns,4))\n",
    "    \n",
    "    for run in range(noOfSamplingRuns):\n",
    "        \n",
    "        trainxs, testxs, trainys, testys  = train_test_split(X,y,train_size=train_size)\n",
    "        \n",
    "        w = minimize(fun = logisticLoss,\n",
    "            x0 = np.random.rand(trainxs.shape[1],),\n",
    "            args = (trainxs, trainys),\n",
    "            method = 'SLSQP',\n",
    "            options = {\"maxiter\":100000},\n",
    "            constraints = []\n",
    "            )\n",
    "    \n",
    "        resultsArray[0,run,0] = 1-errorRate(w.x,trainxs, trainys)\n",
    "        resultsArray[1,run,0] = 1-errorRate(w.x,testxs, testys)\n",
    "\n",
    "        # fairness measures on training data\n",
    "        fairnessMeasure1 = differenceDisparateImpactModel(w.x,trainxs,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "        fairnessMeasure2 = differenceEqualOpportunity(w.x,trainxs,trainys,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "        fairnessMeasure3 = differenceDisparateMistreatment(w.x,trainxs,trainys,sensitiveAttributeIndex=sensitiveAttributeIndex,type='OMR')\n",
    "\n",
    "        resultsArray[0,run,1:] = [np.abs(fairnessMeasure1[0]-fairnessMeasure1[1]),np.abs(fairnessMeasure2[0]-fairnessMeasure2[1]),\\\n",
    "                                 np.abs(fairnessMeasure3[0]-fairnessMeasure3[1])]\n",
    "\n",
    "        # fairness measures on test data\n",
    "        fairnessMeasure1 = differenceDisparateImpactModel(w.x,testxs,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "        fairnessMeasure2 = differenceEqualOpportunity(w.x,testxs,testys,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "        fairnessMeasure3 = differenceDisparateMistreatment(w.x,testxs,testys,sensitiveAttributeIndex=sensitiveAttributeIndex,type='OMR')\n",
    "\n",
    "        resultsArray[1,run,1:] = [np.abs(fairnessMeasure1[0]-fairnessMeasure1[1]),np.abs(fairnessMeasure2[0]-fairnessMeasure2[1]),\\\n",
    "                                 np.abs(fairnessMeasure3[0]-fairnessMeasure3[1])]\n",
    "        \n",
    "    # resultsSummary: \n",
    "    # 1st dimension: train/test\n",
    "    # 2nd dimension: accuracy, fairnessMeasures (x3)\n",
    "    # 3rd dimension: col0: mean, col1: std\n",
    "    resultsSummary = np.zeros((2,4,2))\n",
    "    resultsSummary[:,:,0] = np.nanmean(resultsArray, axis=1)\n",
    "    resultsSummary[:,:,1] = np.nanstd(resultsArray, axis=1)\n",
    "    \n",
    "    return resultsSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitive attributes list:\n",
    "\n",
    "adult: 8 - race, 9 - gender ;  variables = 15 ; 45222 samples\n",
    "\n",
    "bank: 0 - age ; variables = 21 ; 41188 samples\n",
    "\n",
    "german: 6 - gender, 9 - age, 14 - foreign worker ; variables = 25 ; 1000 samples\n",
    "\n",
    "mortgage: 12 - ethnicity, 14 - race, 16 - gender, 24 - minority population ; variables = 30 ; 200000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21)\n",
      "(41188, 20)\n",
      "age: 0\n",
      "A smaller version of the dataset is loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nigelkingsman/Documents/Education/UCL ML/Project/algorithm auditing/myCode/fairness_functions.py:125: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  p_yHatEqualY_z1 = n_yHatEqualY_z1 / n_z1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Bank', '0.9793 $\\\\pm$ 0.0013', '0.0213 $\\\\pm$ 0.0174', '0.2661 $\\\\pm$ 0.0588', '0.0723 $\\\\pm$ 0.0325', '0.9806 $\\\\pm$ 0.0043', '0.0099 $\\\\pm$ 0.0039', '0.2840 $\\\\pm$ 0.1569', '0.0779 $\\\\pm$ 0.1183']\n"
     ]
    }
   ],
   "source": [
    "# sensitiveAttributeList = ['Age','Age','Gender','Gender','Gender','Race','Race']\n",
    "# datasetList = ['Bank','German','Adult','German','Mortgage','Adult','Mortgage']\n",
    "# sensitiveAttributeIndexList = [0,9,9,6,16,8,14]\n",
    "\n",
    "sensitiveAttributeList = ['Age']\n",
    "datasetList = ['Bank']\n",
    "sensitiveAttributeIndexList = [0]\n",
    "\n",
    "cell_text = []\n",
    "\n",
    "for topLevelRun in range(len(sensitiveAttributeList)):   \n",
    "    sensitiveAttributeIndex = sensitiveAttributeIndexList[topLevelRun]\n",
    "    dataset = datasetList[topLevelRun]\n",
    "    X,y = getDataset(dataset.lower())\n",
    "    \n",
    "    # resultsSummary: \n",
    "    # 1st dimension: train/test\n",
    "    # 2nd dimension: accuracy, fairnessMeasures (x3)\n",
    "    # 3rd dimension: col0: mean, col1: std\n",
    "    resultsSummary = computeUnconstrainedMeasures_fullRandomisation(X,y,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "    \n",
    "    cell_text_row = []\n",
    "    cell_text_row.append(sensitiveAttributeList[topLevelRun])\n",
    "    cell_text_row.append(datasetList[topLevelRun])\n",
    "    for i in range(resultsSummary.shape[0]):\n",
    "        for j in range(resultsSummary.shape[1]):\n",
    "            cell_text_row.append('{:.4f} $\\pm$ {:.4f}'.format(resultsSummary[i,j,0], resultsSummary[i,j,1]))\n",
    "\n",
    "    print(cell_text_row)\n",
    "    \n",
    "    cell_text.append(cell_text_row)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
