{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from platypus import Hypervolume, display, calculate, CMAES, MOEAD, NSGAII, NSGAIII, SPEA2, IBEA, Problem, Real\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from bias_functions import *\n",
    "from utility_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(setSelection):\n",
    "    if setSelection == 'toy':\n",
    "        X,y = generate_toy_data(1000,200,2)\n",
    "    elif setSelection == 'adult':\n",
    "        protectedAttributes={'race':'White','gender':'Male'}\n",
    "        X,y = load_adult(protectedAttributes=protectedAttributes)\n",
    "    elif setSelection == 'bank':\n",
    "        X,y = load_bank()\n",
    "    elif setSelection == 'german':\n",
    "        X,y = load_german()\n",
    "    elif setSelection == 'mortgage':\n",
    "        protectedCategoricalAttributes={'applicant_ethnicity_name':'Not Hispanic or Latino',\n",
    "                                'applicant_race_name_1':'White','applicant_sex_name':'Male'}\n",
    "        protectedNumericalAttributes=['minority_population']\n",
    "        X,y = load_mortgage(protectedCategoricalAttributes=protectedCategoricalAttributes, \\\n",
    "                            protectedNumericalAttributes=protectedNumericalAttributes)\n",
    "    else:\n",
    "        print('dataset not recognised')\n",
    "        \n",
    "    X = np.hstack([X, np.ones((X.shape[0],1))]) ## add ones to solve for affine functions\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing problems\n",
    "\n",
    "# problem 1: quadriato, adult dataset, sensistive attribute = gender (9), train/test = 0.8/0.2\n",
    "# objectives: accuracy, DM(OMR)\n",
    "\n",
    "def problem1_base(w,X,y,sensitiveAttributeIndex):\n",
    "    errorRateObjective = errorRate(w,X,y)\n",
    "    fairnessObjective= differenceDisparateMistreatment(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex,type='OMR')\n",
    "    return errorRateObjective, np.abs(fairnessObjective[0]-fairnessObjective[1])\n",
    "\n",
    "def problem1_train(w):\n",
    "    return problem1_base(w,trainxs,trainys,sensitiveAttributeIndex=9)\n",
    "def problem1_test(w):\n",
    "    return problem1_base(w,testxs,testys,sensitiveAttributeIndex=9)\n",
    "\n",
    "# problem 1 (amended): quadriato, adult dataset, sensistive attribute = gender (9), train/test = 0.8/0.2\n",
    "# objectives: accuracy, DM(OMR), DM(FPR), DM(FNR)\n",
    "\n",
    "def problem1amended_base(w,X,y,sensitiveAttributeIndex):\n",
    "    errorRateObjective = errorRate(w,X,y)\n",
    "    fairnessObjective1 = differenceDisparateMistreatment(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex,type='OMR')\n",
    "    fairnessObjective2 = differenceDisparateMistreatment(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex,type='FNR')\n",
    "    fairnessObjective3 = differenceDisparateMistreatment(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex,type='FPR')\n",
    "    return errorRateObjective, np.abs(fairnessObjective1[0]-fairnessObjective1[1]), np.abs(fairnessObjective2[0]-fairnessObjective2[1]), np.abs(fairnessObjective3[0]-fairnessObjective3[1])\n",
    "\n",
    "def problem1amended_train(w):\n",
    "    return problem1amended_base(w,trainxs,trainys,sensitiveAttributeIndex=9)\n",
    "def problem1amended_test(w):\n",
    "    return problem1amended_base(w,testxs,testys,sensitiveAttributeIndex=9)\n",
    "\n",
    "# problem 2: zafar, bank dataset, sensistive attribute = age (0), train/test = 0.7/0.3\n",
    "# objectives: accuracy, DI\n",
    "\n",
    "def problem2_base(w,X,y,sensitiveAttributeIndex):\n",
    "    errorRateObjective = errorRate(w,X,y)\n",
    "    fairnessObjective= differenceDisparateImpactModel(w,X,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "    return errorRateObjective, np.abs(fairnessObjective[0]-fairnessObjective[1])\n",
    "\n",
    "def problem2_train(w):\n",
    "    return problem2_base(w,trainxs,trainys,sensitiveAttributeIndex=0)\n",
    "def problem2_test(w):\n",
    "    return problem2_base(w,testxs,testys,sensitiveAttributeIndex=0)\n",
    "\n",
    "# problem 3: donini, german dataset, sensistive attribute = race (14), train/test = 1.0/0.0\n",
    "# objectives: accuracy, DI\n",
    "\n",
    "def problem3_base(w,X,y,sensitiveAttributeIndex):\n",
    "    errorRateObjective = errorRate(w,X,y)\n",
    "    fairnessObjective= differenceEqualOpportunity(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex)\n",
    "    return errorRateObjective, np.abs(fairnessObjective[0]-fairnessObjective[1])\n",
    "\n",
    "def problem3_train(w):\n",
    "    return problem3_base(w,trainxs,trainys,sensitiveAttributeIndex=14)\n",
    "def problem3_test(w):\n",
    "    return problem3_base(w,testxs,testys,sensitiveAttributeIndex=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitive attributes list:\n",
    "\n",
    "adult: 8 - race, 9 - gender ;  variables = 15 ; 45222 samples\n",
    "\n",
    "bank: 0 - age ; variables = 21 ; 41188 samples\n",
    "\n",
    "german: 6 - gender, 9 - age, 14 - foreign worker ; variables = 25 ; 1000 samples\n",
    "\n",
    "mortgage: 12 - ethnicity, 14 - race, 16 - gender, 24 - minority population ; variables = 30 ; 200000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 32561\n",
      "testing: 16281\n",
      "(45222, 15)\n",
      "(45222, 14)\n",
      "race: 8\n",
      "gender: 9\n",
      "The dataset is loaded...\n",
      "0: training took 0.31 seconds w/ hypervolume 0.725201\n",
      "0: testing took 0.07 seconds w/ hypervolume 0.730425\n",
      "[[0.72520074 0.         0.         0.31281376]\n",
      " [0.73042529 0.         0.         0.07196009]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nigelkingsman/opt/miniconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "# these lines define the problem, test problem, dataset, algorithm and number of sampling runs\n",
    "noOfVariables = 15\n",
    "noOfObjectives = 2\n",
    "\n",
    "problem = Problem(noOfVariables,noOfObjectives)\n",
    "problem.function = problem1_train\n",
    "\n",
    "testProblem = Problem(noOfVariables,noOfObjectives)\n",
    "testProblem.function = problem1_test\n",
    "\n",
    "dataset = 'adult'\n",
    "trainAlgorithm = CMAES(problem)\n",
    "# trainAlgorithm = MOEAD(problem)\n",
    "# trainAlgorithm = NSGAII(problem)\n",
    "# trainAlgorithm = NSGAIII(problem, divisions_outer=96)\n",
    "# trainAlgorithm = SPEA2(problem)\n",
    "# trainAlgorithm = IBEA(problem)\n",
    "\n",
    "noOfSamplingRuns = 1\n",
    "\n",
    "X,y = getDataset(dataset)\n",
    "\n",
    "problem.types[:] = Real(-5,5)\n",
    "\n",
    "hypervolumeArray = np.zeros((noOfSamplingRuns, 2)) # col 0 for training results (hypervolume), col 1 for test results\n",
    "extremesArray = np.zeros((2, noOfObjectives, noOfObjectives, noOfSamplingRuns)) # the first dimension is for train/test\n",
    "averagePointArray = np.zeros((2, noOfSamplingRuns, noOfObjectives)) # the first dimension is for train/test. This array holds the average objective point for each run\n",
    "\n",
    "# these will be used to store the algorithm that returns the largest hypervolume\n",
    "bestTrainAlgorithm = None\n",
    "bestTrainHypervolume = 0\n",
    "bestTestAlgorithm = None\n",
    "bestTestHypervolume = 0\n",
    "totalTrainTime = 0\n",
    "totalTestTime = 0\n",
    "\n",
    "for run in range(noOfSamplingRuns):\n",
    "\n",
    "    # generate new train/test split for each run\n",
    "    trainxs, testxs, trainys, testys  = train_test_split(X,y,train_size=0.8)\n",
    "\n",
    "    # for German dataset only\n",
    "#     trainxs = X\n",
    "#     trainys = y\n",
    "#     testxs = X\n",
    "#     testys = y\n",
    "    \n",
    "    \n",
    "    # training run\n",
    "    startTime = time.perf_counter()\n",
    "    trainAlgorithm.run(10)\n",
    "\n",
    "    trainHyp = Hypervolume(minimum=[0]*noOfObjectives,maximum=[1]*noOfObjectives)\n",
    "    trainHypResult = trainHyp(trainAlgorithm.result)  \n",
    "    hypervolumeArray[run, 0] = trainHypResult\n",
    "    \n",
    "    singleRunExtremesArray, averagePoint = findExtremes_averagePoint(trainAlgorithm)\n",
    "    extremesArray[0,:,:,run] = singleRunExtremesArray\n",
    "    averagePointArray[0,run,:] = averagePoint\n",
    "    \n",
    "    endTime = time.perf_counter()\n",
    "    trainTime = endTime - startTime\n",
    "    totalTrainTime += trainTime\n",
    "    \n",
    "    print(\"{}: training took {:.2f} seconds w/ hypervolume {:2f}\".format(run, trainTime, trainHypResult))\n",
    "    \n",
    "    \n",
    "    # test run\n",
    "    testAlgorithm = deepcopy(trainAlgorithm)\n",
    "\n",
    "    startTime = time.perf_counter()\n",
    "\n",
    "    for resultNumber, result in enumerate(testAlgorithm.result):\n",
    "\n",
    "        w=result.variables\n",
    "        objectivesResult = testProblem.function(w)\n",
    "\n",
    "        # copy objective results individually to the testAlgorithm object\n",
    "        for i in range(len(objectivesResult)):  \n",
    "            testAlgorithm.result[resultNumber].objectives[i]=objectivesResult[i]\n",
    "\n",
    "    testHyp = Hypervolume(minimum=[0]*noOfObjectives,maximum=[1]*noOfObjectives)\n",
    "    testHypResult = testHyp(testAlgorithm.result)\n",
    "    hypervolumeArray[run, 1] = testHypResult\n",
    "    \n",
    "    singleRunExtremesArray, averagePoint = findExtremes_averagePoint(testAlgorithm)\n",
    "    extremesArray[1,:,:,run] = singleRunExtremesArray\n",
    "    averagePointArray[1,run,:] = averagePoint\n",
    "    \n",
    "    endTime = time.perf_counter()\n",
    "    testTime = endTime - startTime\n",
    "    totalTestTime += testTime\n",
    "\n",
    "    print(\"{}: testing took {:.2f} seconds w/ hypervolume {:2f}\".format(run, testTime, testHypResult))\n",
    "    \n",
    "    if trainHypResult > bestTrainHypervolume:\n",
    "        bestTrainHypervolume = trainHypResult\n",
    "        bestTrainAlgorithm = deepcopy(trainAlgorithm)\n",
    "        \n",
    "        bestTestHypervolume = testHypResult\n",
    "        bestTestAlgorithm = deepcopy(testAlgorithm)\n",
    "        \n",
    "#         bestData = [trainxs, testxs, trainys, testys]\n",
    "        bestData = [trainxs, testxs]\n",
    "        bestDataSavePath = \"saved_data/\"+now.strftime(\"%Y%m%d_%H%M\")+\"_\"+str(problem.function)[10:18]+\"_\"+dataset+\"_\"+str(trainAlgorithm)[21:-26]+\"_data\"\n",
    "        np.save(bestDataSavePath, bestData)\n",
    "\n",
    "# resultsSummary:\n",
    "# column 0: average hypervolume, column 1: hypervolume std, column 2: average point std (Euclidean distance), column 3: average time\n",
    "# row 0: training data, row 1: test data\n",
    "resultsSummary = np.zeros((2,4)) \n",
    "resultsMean = np.sum(hypervolumeArray, axis=0)/noOfSamplingRuns \n",
    "resultsSummary[:,0] = resultsMean\n",
    "resultsSummary[:,1] = np.sqrt(np.sum((hypervolumeArray - resultsMean)**2, axis=0)/noOfSamplingRuns)\n",
    "averagePointMeans = np.mean(averagePointArray,axis=1)\n",
    "resultsSummary[0,2] = np.std(np.sqrt(np.sum((averagePointArray[0,:,:]-averagePointMeans[0,:])**2,axis=1)))\n",
    "resultsSummary[1,2] = np.std(np.sqrt(np.sum((averagePointArray[1,:,:]-averagePointMeans[1,:])**2,axis=1)))\n",
    "resultsSummary[0,3] = totalTrainTime/noOfSamplingRuns\n",
    "resultsSummary[1,3] = totalTestTime/noOfSamplingRuns\n",
    "print(resultsSummary)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
