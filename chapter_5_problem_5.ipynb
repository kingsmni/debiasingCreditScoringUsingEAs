{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from platypus import Hypervolume, display, calculate, CMAES, MOEAD, NSGAII, NSGAIII, SPEA2, IBEA, Problem, Real\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from bias_functions import *\n",
    "from utility_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(setSelection):\n",
    "    if setSelection == 'toy':\n",
    "        X,y = generate_toy_data(1000,200,2)\n",
    "    elif setSelection == 'adult':\n",
    "        protectedAttributes={'race':'White','gender':'Male'}\n",
    "        X,y = load_adult(protectedAttributes=protectedAttributes)\n",
    "    elif setSelection == 'bank':\n",
    "        X,y = load_bank()\n",
    "    elif setSelection == 'german':\n",
    "        X,y = load_german()\n",
    "    elif setSelection == 'mortgage':\n",
    "        protectedCategoricalAttributes={'applicant_ethnicity_name':'Not Hispanic or Latino',\n",
    "                                'applicant_race_name_1':'White','applicant_sex_name':'Male'}\n",
    "        protectedNumericalAttributes=['minority_population']\n",
    "        X,y = load_mortgage(protectedCategoricalAttributes=protectedCategoricalAttributes, \\\n",
    "                            protectedNumericalAttributes=protectedNumericalAttributes)\n",
    "    else:\n",
    "        print('dataset not recognised')\n",
    "        \n",
    "    X = np.hstack([X, np.ones((X.shape[0],1))]) ## add ones to solve for affine functions\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new problems\n",
    "\n",
    "# problem 5: datasets {Adult, German, Mortgage} and {age,gender,race} [change dataset in main loop ; change senstitive attributes in _train and _test functions]\n",
    "# objectives: accuracy, DI, EO, DM(OMR) across 2 attributes\n",
    "\n",
    "def problem8_base(w,X,y,sensitiveAttributeIndex1,sensitiveAttributeIndex2):\n",
    "    errorRateObjective = errorRate(w,X,y)\n",
    "    fairnessObjective1 = differenceDisparateImpactModel(w,X,sensitiveAttributeIndex=sensitiveAttributeIndex1)\n",
    "    fairnessObjective2 = differenceDisparateImpactModel(w,X,sensitiveAttributeIndex=sensitiveAttributeIndex2)\n",
    "    fairnessObjective3 = differenceEqualOpportunity(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex1)\n",
    "    fairnessObjective4 = differenceEqualOpportunity(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex2)\n",
    "    fairnessObjective5 = differenceDisparateMistreatment(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex1,type='OMR')\n",
    "    fairnessObjective6 = differenceDisparateMistreatment(w,X,y,sensitiveAttributeIndex=sensitiveAttributeIndex2,type='OMR')\n",
    "    return errorRateObjective,\\\n",
    "max(np.abs(fairnessObjective1[0]-fairnessObjective1[1]),np.abs(fairnessObjective2[0]-fairnessObjective2[1])),\\\n",
    "max(np.abs(fairnessObjective3[0]-fairnessObjective3[1]),np.abs(fairnessObjective4[0]-fairnessObjective4[1])),\\\n",
    "max(np.abs(fairnessObjective5[0]-fairnessObjective5[1]),np.abs(fairnessObjective6[0]-fairnessObjective6[1]))\n",
    "\n",
    "def problem8_train(w):\n",
    "    return problem8_base(w,trainxs,trainys,sensitiveAttributeIndex1=sensitiveAttributeIndex1,sensitiveAttributeIndex2=sensitiveAttributeIndex2)\n",
    "def problem8_test(w):\n",
    "    return problem8_base(w,testxs,testys,sensitiveAttributeIndex1=sensitiveAttributeIndex1,sensitiveAttributeIndex2=sensitiveAttributeIndex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetValue = 0.01\n",
    "targetMeasureArray = np.array([[np.inf,np.inf,np.inf],[targetValue,np.inf,np.inf],\\\n",
    "                             [np.inf,targetValue,np.inf],[np.inf,np.inf,targetValue],\\\n",
    "                             [targetValue,targetValue,np.inf],[targetValue,np.inf,targetValue],\\\n",
    "                             [np.inf,targetValue,targetValue],[targetValue,targetValue,targetValue]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitive attributes list:\n",
    "\n",
    "adult: 8 - race, 9 - gender ;  variables = 15 ; 45222 samples\n",
    "\n",
    "bank: 0 - age ; variables = 21 ; 41188 samples\n",
    "\n",
    "german: 6 - gender, 9 - age, 14 - foreign worker ; variables = 25 ; 1000 samples\n",
    "\n",
    "mortgage: 12 - ethnicity, 14 - race, 16 - gender, 24 - minority population ; variables = 30 ; 200000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 30)\n",
      "(200000, 29)\n",
      "Protected Categorical Attributes:\n",
      "applicant_ethnicity_name: 12\n",
      "applicant_race_name_1: 14\n",
      "applicant_sex_name: 16\n",
      "Protected Numerical Attributes:\n",
      "minority_population: 24\n",
      "The dataset is loaded...\n",
      "0: training took 614.25 seconds w/ hypervolume 0.854966\n",
      "0: testing took 32.60 seconds w/ hypervolume 0.853205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nigelkingsman/opt/miniconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: training took 593.92 seconds w/ hypervolume 0.862134\n",
      "1: testing took 55.68 seconds w/ hypervolume 0.863481\n",
      "2: training took 1905.46 seconds w/ hypervolume 0.861489\n",
      "2: testing took 208.49 seconds w/ hypervolume 0.861940\n",
      "3: training took 1214.36 seconds w/ hypervolume 0.865146\n",
      "3: testing took 340.52 seconds w/ hypervolume 0.863374\n",
      "4: training took 8572.56 seconds w/ hypervolume 0.857015\n",
      "4: testing took 92.57 seconds w/ hypervolume 0.854128\n",
      "5: training took 1029.33 seconds w/ hypervolume 0.868115\n",
      "5: testing took 140.96 seconds w/ hypervolume 0.868456\n",
      "6: training took 629.62 seconds w/ hypervolume 0.858276\n",
      "6: testing took 43.80 seconds w/ hypervolume 0.854485\n",
      "7: training took 659.48 seconds w/ hypervolume 0.861604\n",
      "7: testing took 75.44 seconds w/ hypervolume 0.864474\n",
      "8: training took 682.09 seconds w/ hypervolume 0.866463\n",
      "8: testing took 82.06 seconds w/ hypervolume 0.866364\n",
      "9: training took 734.13 seconds w/ hypervolume 0.867269\n",
      "9: testing took 116.30 seconds w/ hypervolume 0.861341\n",
      "10: training took 857.24 seconds w/ hypervolume 0.863272\n",
      "10: testing took 159.51 seconds w/ hypervolume 0.863859\n",
      "[[8.62340928e-01 4.08915236e-03 1.06781536e-02 1.59022279e+03]\n",
      " [8.61373466e-01 4.92025880e-03 1.06515120e-02 1.22539219e+02]]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "# these lines define the problem, test problem, dataset, algorithm and number of sampling runs\n",
    "noOfObjectives = 4\n",
    "\n",
    "dataset = 'mortgage'\n",
    "\n",
    "if dataset == 'adult':\n",
    "    sensitiveAttributeIndex1 = 9\n",
    "    sensitiveAttributeIndex2 = 8\n",
    "    noOfVariables = 15\n",
    "elif dataset == 'german':\n",
    "    sensitiveAttributeIndex1 = 9\n",
    "    sensitiveAttributeIndex2 = 6\n",
    "    noOfVariables = 25\n",
    "else:\n",
    "    sensitiveAttributeIndex1 = 16\n",
    "    sensitiveAttributeIndex2 = 14\n",
    "    noOfVariables = 30\n",
    "    \n",
    "problem = Problem(noOfVariables,noOfObjectives)\n",
    "problem.function = problem8_train\n",
    "\n",
    "testProblem = Problem(noOfVariables,noOfObjectives)\n",
    "testProblem.function = problem8_test\n",
    "\n",
    "\n",
    "\n",
    "noOfSamplingRuns = 20\n",
    "\n",
    "X,y = getDataset(dataset)\n",
    "\n",
    "problem.types[:] = Real(-5,5)\n",
    "\n",
    "hypervolumeArray = np.zeros((noOfSamplingRuns, 2)) # col 0 for training results (hypervolume), col 1 for test results\n",
    "extremesArray = np.zeros((2, noOfObjectives, noOfObjectives, noOfSamplingRuns)) # the first dimension is for train/test\n",
    "averagePointArray = np.zeros((2, noOfSamplingRuns, noOfObjectives)) # the first dimension is for train/test. This array holds the average objective point for each run\n",
    "\n",
    "overallErrorRateSet = np.zeros((2, noOfSamplingRuns, len(targetMeasureArray)))\n",
    "\n",
    "# these will be used to store the algorithm that returns the largest hypervolume\n",
    "bestTrainAlgorithm = None\n",
    "bestTrainHypervolume = 0\n",
    "bestTestAlgorithm = None\n",
    "bestTestHypervolume = 0\n",
    "totalTrainTime = 0\n",
    "totalTestTime = 0\n",
    "\n",
    "for run in range(noOfSamplingRuns):\n",
    "\n",
    "    # generate new train/test split for each run\n",
    "    trainxs, testxs, trainys, testys  = train_test_split(X,y,train_size=0.8)  \n",
    "    \n",
    "    # training run\n",
    "    startTime = time.perf_counter()\n",
    "    \n",
    "    trainAlgorithm = CMAES(problem)\n",
    "    trainAlgorithm.run(10000)\n",
    "\n",
    "    trainHyp = Hypervolume(minimum=[0]*noOfObjectives,maximum=[1]*noOfObjectives)\n",
    "    trainHypResult = trainHyp(trainAlgorithm.result)  \n",
    "    hypervolumeArray[run, 0] = trainHypResult\n",
    "    \n",
    "    singleRunExtremesArray, averagePoint = findExtremes_averagePoint(trainAlgorithm)\n",
    "    extremesArray[0,:,:,run] = singleRunExtremesArray\n",
    "    averagePointArray[0,run,:] = averagePoint\n",
    "    \n",
    "    minErrorRateSet = minErrorRateSet_given_targetMeasuresArray(trainAlgorithm, targetMeasureArray)\n",
    "    overallErrorRateSet[0,run,:] = minErrorRateSet[:,0]\n",
    "    \n",
    "    endTime = time.perf_counter()\n",
    "    trainTime = endTime - startTime\n",
    "    totalTrainTime += trainTime\n",
    "    \n",
    "    print(\"{}: training took {:.2f} seconds w/ hypervolume {:2f}\".format(run, trainTime, trainHypResult))\n",
    "    \n",
    "    \n",
    "    # test run\n",
    "    testAlgorithm = deepcopy(trainAlgorithm)\n",
    "\n",
    "    startTime = time.perf_counter()\n",
    "\n",
    "    for resultNumber, result in enumerate(testAlgorithm.result):\n",
    "\n",
    "        w=result.variables\n",
    "        objectivesResult = testProblem.function(w)\n",
    "\n",
    "        # copy objective results individually to the testAlgorithm object\n",
    "        for i in range(len(objectivesResult)):  \n",
    "            testAlgorithm.result[resultNumber].objectives[i]=objectivesResult[i]\n",
    "\n",
    "    testHyp = Hypervolume(minimum=[0]*noOfObjectives,maximum=[1]*noOfObjectives)\n",
    "    testHypResult = testHyp(testAlgorithm.result)\n",
    "    hypervolumeArray[run, 1] = testHypResult\n",
    "    \n",
    "    singleRunExtremesArray, averagePoint = findExtremes_averagePoint(testAlgorithm)\n",
    "    extremesArray[1,:,:,run] = singleRunExtremesArray\n",
    "    averagePointArray[1,run,:] = averagePoint\n",
    "    \n",
    "    for targetMeasure in range(len(targetMeasureArray)):\n",
    "        if minErrorRateSet[targetMeasure,0] == 1.0:\n",
    "            overallErrorRateSet[1,run,targetMeasure] = 1.0\n",
    "        else:\n",
    "            overallErrorRateSet[1,run,targetMeasure] = testAlgorithm.result[np.int(minErrorRateSet[targetMeasure,1])].objectives[0]\n",
    "    \n",
    "    \n",
    "    endTime = time.perf_counter()\n",
    "    testTime = endTime - startTime\n",
    "    totalTestTime += testTime\n",
    "\n",
    "    print(\"{}: testing took {:.2f} seconds w/ hypervolume {:2f}\".format(run, testTime, testHypResult))\n",
    "    \n",
    "    if trainHypResult > bestTrainHypervolume:\n",
    "        bestTrainHypervolume = trainHypResult\n",
    "        bestTrainAlgorithm = deepcopy(trainAlgorithm)\n",
    "        \n",
    "        bestTestHypervolume = testHypResult\n",
    "        bestTestAlgorithm = deepcopy(testAlgorithm)\n",
    "        \n",
    "        bestData = [trainxs, testxs, trainys, testys]\n",
    "        bestDataSavePath = \"saved_data/\"+now.strftime(\"%Y%m%d_%H%M\")+\"_\"+str(problem.function)[10:18]+\"_\"+dataset+\"_\"+str(trainAlgorithm)[21:-26]+\"_data\"\n",
    "        np.save(bestDataSavePath, bestData)\n",
    "        \n",
    "# resultsSummary:\n",
    "# column 0: average hypervolume, column 1: hypervolume std, column 2: average point std (Euclidean distance), column 3: average time\n",
    "# row 0: training data, row 1: test data\n",
    "resultsSummary = np.zeros((2,4)) \n",
    "resultsMean = np.sum(hypervolumeArray, axis=0)/noOfSamplingRuns \n",
    "resultsSummary[:,0] = resultsMean\n",
    "resultsSummary[:,1] = np.sqrt(np.sum((hypervolumeArray - resultsMean)**2, axis=0)/noOfSamplingRuns)\n",
    "averagePointMeans = np.mean(averagePointArray,axis=1)\n",
    "resultsSummary[0,2] = np.std(np.sqrt(np.sum((averagePointArray[0,:,:]-averagePointMeans[0,:])**2,axis=1)))\n",
    "resultsSummary[1,2] = np.std(np.sqrt(np.sum((averagePointArray[1,:,:]-averagePointMeans[1,:])**2,axis=1)))\n",
    "resultsSummary[0,3] = totalTrainTime/noOfSamplingRuns\n",
    "resultsSummary[1,3] = totalTestTime/noOfSamplingRuns\n",
    "print(resultsSummary) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
